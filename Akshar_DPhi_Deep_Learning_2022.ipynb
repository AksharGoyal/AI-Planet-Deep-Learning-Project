{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYLdlAJ8S04w"
      },
      "source": [
        "# DPhi Deep Learning Bootcamp Datathon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX2MV-lj0sFL"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "First, we will get the zip file. we will use wget so that no matter how many times we refresh, we don't have drag-and-drop the files here. Then we will use zipfile package to extract the files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Ow_BMI3zy1Yh",
        "outputId": "dd385e5f-a3e7-4447-c62f-81704724f66a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to connection timeout. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# !pip install wget\n",
        "import wget\n",
        "link ='https://dphi-live.s3.eu-west-1.amazonaws.com/dataset/weather.zip' # get the zip file\n",
        "wget.download(link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-FXG2tXXJZQ"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/weather.zip', 'r') as zip_ref: # extract the files\n",
        "    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvwO4xgeS0Ui"
      },
      "source": [
        "Then we will import the necessary libraries. Note that all of them were used heavily. Some were used just to get an idea of our data or as debugging statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uWjMVl-zXm9z",
        "outputId": "2f6be2e5-4f48-411a-8899-1417aad69e4c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # to get the dataframe\n",
        "import tensorflow as tf # for deep learning\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # for numerical operations\n",
        "import cv2 # to read or show the image\n",
        "from sklearn.metrics import accuracy_score # to score our model\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array # helpful in getting images\n",
        "from tensorflow.keras.applications import vgg19 # get the model for image classifier\n",
        "\n",
        "train_data = pd.read_csv('Training_set.csv') # read the training data\n",
        "train_data.sample(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeJm5tRoZK2v",
        "outputId": "612cd9ad-c0b6-4ffd-97aa-98d6b6b9d576"
      },
      "outputs": [],
      "source": [
        "train_data.info() # no null data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsPGzsvpY94S",
        "outputId": "d7fa42a8-4251-4091-8469-0cb84c7758f9"
      },
      "outputs": [],
      "source": [
        "np.round(train_data.label.value_counts(normalize=True),4) # get an idea of spread of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "aVSyF28TYZCx",
        "outputId": "462105d6-6734-45e0-bbd2-b72b6f2428b5"
      },
      "outputs": [],
      "source": [
        "sns.countplot(train_data.label)\n",
        "# spread of labels seem balanced\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSFQvYxo149t"
      },
      "source": [
        "## Getting the image data and preparing them for the model\n",
        "\n",
        "We will first get the filepath as they will provide us the image. It is important to use a merging method as the filepaths can be obtained in any order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "EKntdo_2Zdhl",
        "outputId": "2297a1a0-ffc4-478b-fac6-ff786d027ffd"
      },
      "outputs": [],
      "source": [
        "file_paths = [[fname, '/content/train/' + fname] for fname in train_data.filename] # get the paths\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "train_data = pd.merge(images, train_data, on = 'filename')\n",
        "train_data.sample(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnkkwgYE2WCZ"
      },
      "source": [
        "Let us see what some of the images look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "9nnF6S2sePv5",
        "outputId": "d17962e8-20ac-4338-8975-fb1e5de31562"
      },
      "outputs": [],
      "source": [
        "plt.subplots(2,3,True,True, figsize=(10,6))\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(cv2.imread(train_data.filepaths[121]))\n",
        "plt.title(train_data.label[121])\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(cv2.imread(train_data.filepaths[520]))\n",
        "plt.title(train_data.label[520])\n",
        "plt.subplot(2,3,3)\n",
        "plt.imshow(cv2.imread(train_data.filepaths[356]))\n",
        "plt.title(train_data.label[356])\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(cv2.imread(train_data.filepaths[0]))\n",
        "plt.title(train_data.label[0])\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(cv2.imread(train_data.filepaths[109]))\n",
        "plt.title(train_data.label[109])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrGjn2e0aDNK",
        "outputId": "2b371d6c-4abb-45cb-e8a9-0331b525b0bd"
      },
      "outputs": [],
      "source": [
        "data_train = []\n",
        "for i in range(len(train_data)): # get the actual images\n",
        "  img_array = cv2.imread(train_data['filepaths'][i])\n",
        "  new_img_array = cv2.resize(img_array, (150, 150)) # resize them for the sake of consistency\n",
        "  data_train.append(img_to_array(new_img_array)) # append them\n",
        "print(data_train[0].shape) # it is list for now\n",
        "data_train_arr = np.stack(data_train)/255 # make it an array and scale it\n",
        "print(data_train_arr.shape)\n",
        "label_train = train_data.label.astype('category').cat.codes.values # get the labels\n",
        "print(label_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOWAUMEdh9GY"
      },
      "outputs": [],
      "source": [
        "temp = dict(zip(label_train, train_data.label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_GVi-Px3SYs"
      },
      "source": [
        "# Setting up and testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNG6Z9RypkDx",
        "outputId": "4904ab48-aeaa-428d-eb81-a3e842f96d0d"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (150, 150, 3) # define the input size\n",
        "model = tf.keras.models.Sequential() # initialize the model\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),\n",
        "activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # maxpool\n",
        "model.add(tf.keras.layers.Flatten()) # flatten\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3)) # dropout\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3)) # dropout\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax')) # identification\n",
        "# compilation\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "# view model layers\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvFfs8jWqDab",
        "outputId": "f85b1759-029e-4307-e46c-16795a03e224"
      },
      "outputs": [],
      "source": [
        "# callback to avoid unnecessary complete execution\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2,\n",
        "verbose=1)\n",
        "\n",
        "history = model.fit(data_train_arr, label_train, batch_size=64,\n",
        "          callbacks=[es_callback], validation_split=0.3, epochs=100,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ao4dNhPGqmVr",
        "outputId": "7f558d26-a02b-4b69-86df-1b11087d3659"
      },
      "outputs": [],
      "source": [
        "# performance of the model\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\n",
        "history_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmw9wnN3xiK"
      },
      "source": [
        "## VGG19 model\n",
        "\n",
        "We will now VGG19 layer to help improve our model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEaNH0pmrC82"
      },
      "outputs": [],
      "source": [
        "vgg_layers = vgg19.VGG19(weights='imagenet', include_top=False,\n",
        "input_shape=INPUT_SHAPE)\n",
        "for layer in vgg_layers.layers:\n",
        "  layer.trainable = True\n",
        "# vgg_layers.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nafxtGQCtk-y",
        "outputId": "5136cd18-6730-4068-bc78-60a63f0f3b21"
      },
      "outputs": [],
      "source": [
        "# define sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(vgg_layers) # add the vgg19 layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "# compilation\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vailzUGuQPT",
        "outputId": "d135c9e8-19f8-4160-c142-99fffdb394a0"
      },
      "outputs": [],
      "source": [
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
        "verbose=1, min_delta=0.01, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(data_train_arr, label_train, batch_size=32,\n",
        "          callbacks=[es_callback], validation_split=0.3, epochs=100,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Zr2P7_ubvj6Y",
        "outputId": "c7b08d57-2c2f-41a6-b015-1a14fd0995c7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\n",
        "history_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);\n",
        "# With VGG19 the performance is better\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkxTqxonvthW",
        "outputId": "4bdbcb25-ab61-449c-caf9-8005a2db8f39"
      },
      "outputs": [],
      "source": [
        "# test the model on training data\n",
        "valid_labels = np.argmax(model.predict(data_train_arr), axis=1)\n",
        "accuracy_score(valid_labels, label_train)\n",
        "# looks great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnAsE574-OLU"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Now we will generate predictions and submit the file!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC4VcpwewsmY"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('Testing_set.csv')\n",
        "file_paths = [[fname, '/content/test/' + fname] for fname in test_data.filename]\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "test_data = pd.merge(images, test_data, on = 'filename')\n",
        "\n",
        "data_test = []\n",
        "for i in range(len(test_data)):\n",
        "  img_array = cv2.imread(test_data['filepaths'][i])\n",
        "  new_img_array = cv2.resize(img_array, (150, 150))\n",
        "  data_test.append(img_to_array(new_img_array))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-vvvJ1ujMf0"
      },
      "outputs": [],
      "source": [
        "data_test_arr = np.stack(data_test)/255\n",
        "a = np.argmax(model.predict(data_test_arr), axis=1)\n",
        "# print([temp[i] for i in a])\n",
        "predictions = pd.DataFrame([temp[i] for i in a], columns=['label']) # get the original labels \n",
        "# predictions.head()\n",
        "predictions.to_csv('DPhi_Deep_Learning_Akshar.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kAUF9Q6_4wBA",
        "outputId": "a9964ee0-8ffd-42cd-bcba-35ff10ff0dd0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files \n",
        "files.download('DPhi_Deep_Learning_Akshar.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "eMmVfwTziW3k",
        "outputId": "03380840-3298-4d23-a895-cbb98cf6a5fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJKhCyTV9_hI",
        "outputId": "65f714be-f39e-4516-ea4a-cf0410ef891d"
      },
      "outputs": [],
      "source": [
        "rm weather*.zip # to prevent duplicate files when wget code is executed"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Akshar_DPhi_Deep_Learning_2022.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "26fbb4931c97b2111fc2ae74c480fac86a91916c431186e43fd66dfbd1084d3e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
